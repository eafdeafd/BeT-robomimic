
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_eef_pos', 'object']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []
/home/andrew/Desktop/robo_sims/robomimic/robomimic/scripts

============= Loaded Environment Metadata =============
obs key object with shape (10,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name Lift
Action size is 7
Lift
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}


============= Model Summary =============
BET (
  ModuleDict(
    (mlp): MLP(
        input_dim=7
        output_dim=7
        layer_dims=[512, 512]
        layer_func=Linear
        dropout=None
        act=Mish
        output_act=Tanh
    )
    (policy): MinGPT(
      (model): GPT(
        (tok_emb): Linear(in_features=26, out_features=72, bias=True)
        (drop): Dropout(p=0.1, inplace=False)
        (blocks): Sequential(
          (0): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (1): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (2): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (3): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (ln_f): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
        (head): Linear(in_features=72, out_features=512, bias=False)
      )
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 48%|####7     | 86/180 [00:00<00:00, 850.76it/s] 96%|#########5| 172/180 [00:00<00:00, 843.18it/s]100%|##########| 180/180 [00:00<00:00, 844.16it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/8640 [00:00<?, ?it/s] 15%|#5        | 1296/8640 [00:00<00:00, 12957.05it/s] 30%|###       | 2598/8640 [00:00<00:00, 12993.54it/s] 45%|####5     | 3898/8640 [00:00<00:00, 12864.16it/s] 60%|######    | 5185/8640 [00:00<00:00, 12863.87it/s] 75%|#######4  | 6472/8640 [00:00<00:00, 12835.82it/s] 90%|########9 | 7756/8640 [00:00<00:00, 12795.92it/s]100%|##########| 8640/8640 [00:00<00:00, 12861.80it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 871.05it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/1026 [00:00<?, ?it/s]100%|##########| 1026/1026 [00:00<00:00, 13009.68it/s]

============= Training Dataset =============
SequenceDataset (
	path=/home/andrew/Desktop/robo_sims/robomimic/datasets/lift/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=all
	num_demos=180
	num_sequences=8640
)

  0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:   0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:  13%|#3        | 13/100 [00:00<00:00, 129.78it/s]K-means clustering:  27%|##7       | 27/100 [00:00<00:00, 135.54it/s]K-means clustering:  43%|####3     | 43/100 [00:00<00:00, 144.31it/s]K-means clustering:  59%|#####8    | 59/100 [00:00<00:00, 148.31it/s]K-means clustering:  75%|#######5  | 75/100 [00:00<00:00, 151.28it/s]K-means clustering:  91%|#########1| 91/100 [00:00<00:00, 152.01it/s]K-means clustering: 100%|##########| 100/100 [00:00<00:00, 148.66it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  1%|1         | 1/100 [00:00<00:17,  5.60it/s]  9%|9         | 9/100 [00:00<00:02, 36.76it/s] 17%|#7        | 17/100 [00:00<00:01, 51.16it/s] 25%|##5       | 25/100 [00:00<00:01, 57.94it/s] 33%|###3      | 33/100 [00:00<00:01, 62.62it/s] 41%|####1     | 41/100 [00:00<00:00, 66.19it/s] 49%|####9     | 49/100 [00:00<00:00, 68.82it/s] 57%|#####6    | 57/100 [00:00<00:00, 70.03it/s] 65%|######5   | 65/100 [00:01<00:00, 71.22it/s] 73%|#######3  | 73/100 [00:01<00:00, 71.88it/s] 81%|########1 | 81/100 [00:01<00:00, 72.50it/s] 89%|########9 | 89/100 [00:01<00:00, 72.55it/s] 97%|#########7| 97/100 [00:01<00:00, 72.48it/s]100%|##########| 100/100 [00:01<00:00, 64.92it/s]
Train Epoch 1
{
    "Cosine_Loss": 0.6760087895393372,
    "L1_Loss": 0.09982288904488086,
    "L2_Loss": 0.2040984646975994,
    "Loss": 4.585784330368042,
    "Policy_Grad_Norms": 0.7707548225354413,
    "Time_Data_Loading": 0.0028084238370259603,
    "Time_Epoch": 0.025683510303497314,
    "Time_Log_Info": 6.63161277770996e-05,
    "Time_Process_Batch": 0.00042510430018107096,
    "Time_Train_Batch": 0.022332823276519774
}
  0%|          | 0/10 [00:00<?, ?it/s]100%|##########| 10/10 [00:00<00:00, 222.23it/s]
Validation Epoch 1
{
    "Cosine_Loss": 0.6800722718238831,
    "L1_Loss": 0.08424415364861489,
    "L2_Loss": 0.17079086750745773,
    "Loss": 4.3770363330841064,
    "Time_Data_Loading": 0.00028215646743774415,
    "Time_Epoch": 0.0007624546686808268,
    "Time_Log_Info": 5.829334259033203e-06,
    "Time_Process_Batch": 5.4335594177246095e-05,
    "Time_Train_Batch": 0.0004065752029418945
}

Epoch 1 Memory Usage: 3670 MB

  0%|          | 0/100 [00:00<?, ?it/s]  8%|8         | 8/100 [00:00<00:01, 70.37it/s] 16%|#6        | 16/100 [00:00<00:01, 71.26it/s] 24%|##4       | 24/100 [00:00<00:01, 71.81it/s] 32%|###2      | 32/100 [00:00<00:00, 71.68it/s] 40%|####      | 40/100 [00:00<00:00, 71.76it/s] 48%|####8     | 48/100 [00:00<00:00, 72.23it/s] 56%|#####6    | 56/100 [00:00<00:00, 72.71it/s] 64%|######4   | 64/100 [00:00<00:00, 73.01it/s] 72%|#######2  | 72/100 [00:00<00:00, 73.41it/s] 80%|########  | 80/100 [00:01<00:00, 73.67it/s] 88%|########8 | 88/100 [00:01<00:00, 73.67it/s] 96%|#########6| 96/100 [00:01<00:00, 73.81it/s]100%|##########| 100/100 [00:01<00:00, 72.86it/s]
Train Epoch 2
{
    "Cosine_Loss": 0.40655784741044043,
    "L1_Loss": 0.04439576843753457,
    "L2_Loss": 0.09467666532844304,
    "Loss": 4.040719041824341,
    "Policy_Grad_Norms": 0.9999998905195214,
    "Time_Data_Loading": 0.0028070767720540365,
    "Time_Epoch": 0.02288539012273153,
    "Time_Log_Info": 6.758769353230795e-05,
    "Time_Process_Batch": 0.0004289070765177409,
    "Time_Train_Batch": 0.019534190495808918
}
  0%|          | 0/10 [00:00<?, ?it/s]100%|##########| 10/10 [00:00<00:00, 225.27it/s]
Validation Epoch 2
{
    "Cosine_Loss": 0.34252033531665804,
    "L1_Loss": 0.03577863089740276,
    "L2_Loss": 0.07764984667301178,
    "Loss": 3.8946031093597413,
    "Time_Data_Loading": 0.00026830434799194334,
    "Time_Epoch": 0.0007564028104146322,
    "Time_Log_Info": 2.3587544759114584e-05,
    "Time_Process_Batch": 3.9788087209065753e-05,
    "Time_Train_Batch": 0.0004070599873860677
}

Epoch 2 Memory Usage: 3670 MB

Traceback (most recent call last):
  File "multitask_train.py", line 23, in <module>
    model = train(config, device=device, model=model)
TypeError: train() got an unexpected keyword argument 'model'
