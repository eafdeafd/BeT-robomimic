
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_eef_pos', 'object']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []
/home/andrew/Desktop/robo_sims/robomimic

============= Loaded Environment Metadata =============
obs key object with shape (10,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name Lift
Action size is 7
Lift
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}


============= Model Summary =============
ObservationKeyToModalityDict: action not found, adding action to mapping with assumed low_dim modality!
BET (
  ModuleDict(
    (encoder): ObservationBETGroupEncoder(
        group=obs
        ObservationEncoder(
            Key(
                name=object
                shape=[10]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_pos
                shape=[3]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_quat
                shape=[4]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_gripper_qpos
                shape=[2]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            output_shape=[19]
        )
    )
    (ac_encoder): ObservationGroupEncoder(
        group=obs
        ObservationEncoder(
            Key(
                name=object
                shape=[10]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_pos
                shape=[3]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_quat
                shape=[4]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_gripper_qpos
                shape=[2]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            output_shape=[19]
        )
    )
    (mlp): MLP(
        input_dim=19
        output_dim=400
        layer_dims=(300,)
        layer_func=Linear
        dropout=None
        act=Mish
        output_act=Mish
    )
    (decoder): ObservationDecoder(
        Key(
            name=action
            shape=(7,)
            modality=low_dim
            net=(Linear(in_features=400, out_features=7, bias=True))
        )
    )
    (policy): MinGPT(
      (model): GPT(
        (tok_emb): Linear(in_features=19, out_features=120, bias=True)
        (drop): Dropout(p=0.1, inplace=False)
        (blocks): Sequential(
          (0): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (1): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (2): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (3): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (4): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (5): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (ln_f): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
        (head): Linear(in_features=120, out_features=256, bias=False)
      )
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 50%|#####     | 90/180 [00:00<00:00, 897.45it/s]100%|##########| 180/180 [00:00<00:00, 888.28it/s]100%|##########| 180/180 [00:00<00:00, 889.02it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/8640 [00:00<?, ?it/s] 16%|#5        | 1352/8640 [00:00<00:00, 13517.66it/s] 31%|###1      | 2704/8640 [00:00<00:00, 13497.50it/s] 47%|####6     | 4054/8640 [00:00<00:00, 13457.79it/s] 63%|######2   | 5420/8640 [00:00<00:00, 13534.18it/s] 79%|#######8  | 6798/8640 [00:00<00:00, 13622.05it/s] 94%|#########4| 8163/8640 [00:00<00:00, 13631.06it/s]100%|##########| 8640/8640 [00:00<00:00, 13564.17it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 907.78it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/1026 [00:00<?, ?it/s]100%|##########| 1026/1026 [00:00<00:00, 13578.04it/s]

============= Training Dataset =============
SequenceDataset (
	path=datasets/lift/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=all
	num_demos=180
	num_sequences=8640
)

  0%|          | 0/50 [00:00<?, ?it/s]K-means clustering:   0%|          | 0/50 [00:00<?, ?it/s]K-means clustering:   6%|6         | 3/50 [00:00<00:01, 29.95it/s]K-means clustering:  12%|#2        | 6/50 [00:00<00:01, 29.87it/s]K-means clustering:  18%|#8        | 9/50 [00:00<00:01, 29.76it/s]K-means clustering:  24%|##4       | 12/50 [00:00<00:01, 29.40it/s]K-means clustering:  30%|###       | 15/50 [00:00<00:01, 29.51it/s]K-means clustering:  36%|###6      | 18/50 [00:00<00:01, 28.90it/s]K-means clustering:  42%|####2     | 21/50 [00:00<00:00, 29.24it/s]K-means clustering:  48%|####8     | 24/50 [00:00<00:00, 29.39it/s]K-means clustering:  54%|#####4    | 27/50 [00:00<00:00, 29.55it/s]K-means clustering:  60%|######    | 30/50 [00:01<00:00, 29.68it/s]K-means clustering:  66%|######6   | 33/50 [00:01<00:00, 29.73it/s]K-means clustering:  74%|#######4  | 37/50 [00:01<00:00, 29.83it/s]K-means clustering:  80%|########  | 40/50 [00:01<00:00, 29.84it/s]K-means clustering:  88%|########8 | 44/50 [00:01<00:00, 29.88it/s]K-means clustering:  94%|#########3| 47/50 [00:01<00:00, 29.79it/s]K-means clustering: 100%|##########| 50/50 [00:01<00:00, 29.76it/s]K-means clustering: 100%|##########| 50/50 [00:01<00:00, 29.64it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
run failed with error:
 Error while processing rearrange-reduction pattern "batch (seq o) -> batch seq o".
 Input tensor shape: torch.Size([10, 190]). Additional info: {'batch': 10, 'seq': 3}.
 Shape mismatch, can't divide axis of length 190 in chunks of 3

Traceback (most recent call last):
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/einops/einops.py", line 382, in reduce
    return recipe.apply(tensor)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/einops/einops.py", line 204, in apply
    init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes = self.reconstruct_from_shape(
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/einops/einops.py", line 175, in reconstruct_from_shape
    raise EinopsError("Shape mismatch, can't divide axis of length {} in chunks of {}".format(
einops.EinopsError: Shape mismatch, can't divide axis of length 190 in chunks of 3

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "robomimic/scripts/train.py", line 361, in main
    train(config, device=device)
  File "robomimic/scripts/train.py", line 185, in train
    step_log = TrainUtils.run_epoch(model=model, data_loader=train_loader, epoch=epoch, num_steps=train_num_steps)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 541, in run_epoch
    info = model.train_on_batch(input_batch, epoch, validate=validate)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet.py", line 220, in train_on_batch
    enc_outputs = self.nets["encoder"](self.algo_config.window_size, **{"obs":batch["obs"]})
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/models/obs_nets.py", line 560, in forward
    outputs = einops.rearrange(
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/einops/einops.py", line 452, in rearrange
    return reduce(tensor, pattern, reduction='rearrange', **axes_lengths)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/einops/einops.py", line 390, in reduce
    raise EinopsError(message + '\n {}'.format(e))
einops.EinopsError:  Error while processing rearrange-reduction pattern "batch (seq o) -> batch seq o".
 Input tensor shape: torch.Size([10, 190]). Additional info: {'batch': 10, 'seq': 3}.
 Shape mismatch, can't divide axis of length 190 in chunks of 3

