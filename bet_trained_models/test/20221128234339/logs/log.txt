
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_pos', 'robot0_eef_quat', 'object', 'robot0_gripper_qpos']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []
/home/andrew/Desktop/robo_sims/robomimic

============= Loaded Environment Metadata =============
obs key object with shape (10,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name Lift
Action size is 7
Lift
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}


============= Model Summary =============
ObservationKeyToModalityDict: action not found, adding action to mapping with assumed low_dim modality!
BET (
  ModuleDict(
    (encoder): ObservationBETGroupEncoder(
        group=obs
        ObservationEncoder(
            Key(
                name=object
                shape=[10]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_pos
                shape=[3]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_quat
                shape=[4]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_gripper_qpos
                shape=[2]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            output_shape=[19]
        )
    )
    (ac_encoder): ObservationGroupEncoder(
        group=obs
        ObservationEncoder(
            Key(
                name=object
                shape=[10]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_pos
                shape=[3]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_quat
                shape=[4]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_gripper_qpos
                shape=[2]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            output_shape=[19]
        )
    )
    (mlp): MLP(
        input_dim=19
        output_dim=400
        layer_dims=(300,)
        layer_func=Linear
        dropout=None
        act=Mish
        output_act=Mish
    )
    (decoder): ObservationDecoder(
        Key(
            name=action
            shape=(7,)
            modality=low_dim
            net=(Linear(in_features=400, out_features=7, bias=True))
        )
    )
    (policy): MinGPT(
      (model): GPT(
        (tok_emb): Linear(in_features=19, out_features=120, bias=True)
        (drop): Dropout(p=0.1, inplace=False)
        (blocks): Sequential(
          (0): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (1): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (2): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (3): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (4): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (5): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): Mish()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (ln_f): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
        (head): Linear(in_features=120, out_features=512, bias=False)
      )
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 48%|####8     | 87/180 [00:00<00:00, 866.20it/s] 97%|#########6| 174/180 [00:00<00:00, 864.29it/s]100%|##########| 180/180 [00:00<00:00, 864.10it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/8640 [00:00<?, ?it/s] 17%|#6        | 1438/8640 [00:00<00:00, 14366.48it/s] 34%|###3      | 2917/8640 [00:00<00:00, 14610.59it/s] 51%|#####     | 4390/8640 [00:00<00:00, 14664.33it/s] 68%|######8   | 5885/8640 [00:00<00:00, 14775.35it/s] 85%|########5 | 7376/8640 [00:00<00:00, 14822.61it/s]100%|##########| 8640/8640 [00:00<00:00, 14769.17it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 872.47it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/1026 [00:00<?, ?it/s]100%|##########| 1026/1026 [00:00<00:00, 14450.78it/s]

============= Training Dataset =============
SequenceDataset (
	path=datasets/lift/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=3
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=all
	num_demos=180
	num_sequences=8640
)

  0%|          | 0/50 [00:00<?, ?it/s]K-means clustering:   0%|          | 0/50 [00:00<?, ?it/s]                                                          done step 1/50, re-initialized 1 dead clusters
K-means clustering:   0%|          | 0/50 [00:00<?, ?it/s]K-means clustering:   8%|8         | 4/50 [00:00<00:01, 37.61it/s]K-means clustering:  18%|#8        | 9/50 [00:00<00:01, 40.15it/s]K-means clustering:  28%|##8       | 14/50 [00:00<00:00, 42.17it/s]K-means clustering:  38%|###8      | 19/50 [00:00<00:00, 42.82it/s]K-means clustering:  48%|####8     | 24/50 [00:00<00:00, 43.43it/s]K-means clustering:  58%|#####8    | 29/50 [00:00<00:00, 44.06it/s]K-means clustering:  68%|######8   | 34/50 [00:00<00:00, 44.37it/s]K-means clustering:  78%|#######8  | 39/50 [00:00<00:00, 44.34it/s]K-means clustering:  88%|########8 | 44/50 [00:01<00:00, 44.62it/s]K-means clustering:  98%|#########8| 49/50 [00:01<00:00, 44.67it/s]K-means clustering: 100%|##########| 50/50 [00:01<00:00, 43.73it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  1%|1         | 1/100 [00:00<00:18,  5.31it/s]  8%|8         | 8/100 [00:00<00:02, 32.03it/s] 15%|#5        | 15/100 [00:00<00:01, 44.91it/s] 22%|##2       | 22/100 [00:00<00:01, 50.89it/s] 29%|##9       | 29/100 [00:00<00:01, 55.22it/s] 36%|###6      | 36/100 [00:00<00:01, 58.55it/s] 43%|####3     | 43/100 [00:00<00:00, 60.58it/s] 50%|#####     | 50/100 [00:00<00:00, 62.09it/s] 57%|#####6    | 57/100 [00:01<00:00, 63.01it/s] 64%|######4   | 64/100 [00:01<00:00, 63.40it/s] 71%|#######1  | 71/100 [00:01<00:00, 63.94it/s] 78%|#######8  | 78/100 [00:01<00:00, 64.41it/s] 85%|########5 | 85/100 [00:01<00:00, 64.73it/s] 92%|#########2| 92/100 [00:01<00:00, 64.78it/s] 99%|#########9| 99/100 [00:01<00:00, 64.98it/s]100%|##########| 100/100 [00:01<00:00, 58.20it/s]
Train Epoch 1
{
    "Loss": 11.621911854743958,
    "Policy_Grad_Norms": 1.0000000125340012,
    "Time_Data_Loading": 0.002740955352783203,
    "Time_Epoch": 0.028647351264953613,
    "Time_Log_Info": 0.00011388460795084636,
    "Time_Process_Batch": 0.00026047229766845703,
    "Time_Train_Batch": 0.025471421082814534
}
  0%|          | 0/1000 [00:00<?, ?it/s]  2%|2         | 23/1000 [00:00<00:04, 229.04it/s]  5%|4         | 47/1000 [00:00<00:04, 232.50it/s]  7%|7         | 71/1000 [00:00<00:03, 234.24it/s] 10%|9         | 95/1000 [00:00<00:03, 235.68it/s] 12%|#1        | 119/1000 [00:00<00:03, 236.04it/s] 14%|#4        | 143/1000 [00:00<00:03, 236.93it/s] 17%|#6        | 167/1000 [00:00<00:03, 236.31it/s] 19%|#9        | 191/1000 [00:00<00:03, 236.41it/s] 22%|##1       | 215/1000 [00:00<00:03, 236.85it/s] 24%|##3       | 239/1000 [00:01<00:03, 237.11it/s] 26%|##6       | 263/1000 [00:01<00:03, 236.31it/s] 29%|##8       | 287/1000 [00:01<00:03, 236.67it/s] 31%|###1      | 311/1000 [00:01<00:02, 236.76it/s] 34%|###3      | 335/1000 [00:01<00:02, 235.24it/s] 36%|###5      | 359/1000 [00:01<00:02, 234.52it/s] 38%|###8      | 383/1000 [00:01<00:02, 235.41it/s] 41%|####      | 407/1000 [00:01<00:02, 236.13it/s] 43%|####3     | 431/1000 [00:01<00:02, 236.29it/s] 46%|####5     | 455/1000 [00:01<00:02, 236.51it/s] 48%|####7     | 479/1000 [00:02<00:02, 237.07it/s] 50%|#####     | 503/1000 [00:02<00:02, 236.04it/s] 53%|#####2    | 527/1000 [00:02<00:01, 236.51it/s] 55%|#####5    | 551/1000 [00:02<00:01, 236.90it/s] 57%|#####7    | 575/1000 [00:02<00:01, 236.21it/s] 60%|#####9    | 599/1000 [00:02<00:01, 236.34it/s] 61%|######1   | 614/1000 [00:02<00:01, 235.90it/s]
Traceback (most recent call last):
  File "robomimic/scripts/train.py", line 410, in <module>
    main(args)
  File "robomimic/scripts/train.py", line 361, in main
    train(config, device=device)
  File "robomimic/scripts/train.py", line 216, in train
    step_log = TrainUtils.run_epoch(model=model, data_loader=valid_loader, epoch=epoch, validate=True, num_steps=valid_num_steps)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 526, in run_epoch
    batch = next(data_loader_iter)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    return self.collate_fn(data)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 74, in default_collate
    return {key: default_collate([d[key] for d in batch]) for key in elem}
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 74, in <dictcomp>
    return {key: default_collate([d[key] for d in batch]) for key in elem}
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 74, in default_collate
    return {key: default_collate([d[key] for d in batch]) for key in elem}
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 74, in <dictcomp>
    return {key: default_collate([d[key] for d in batch]) for key in elem}
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 64, in default_collate
    return default_collate([torch.as_tensor(b) for b in batch])
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 64, in <listcomp>
    return default_collate([torch.as_tensor(b) for b in batch])
KeyboardInterrupt
