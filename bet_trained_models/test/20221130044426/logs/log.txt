
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []
/home/andrew/Desktop/robo_sims/robomimic

============= Loaded Environment Metadata =============
obs key object with shape (10,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name Lift
Action size is 7
Lift
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}


============= Model Summary =============
BET (
  ModuleDict(
    (encoder): ObservationBETGroupEncoder(
        group=obs
        ObservationEncoder(
            Key(
                name=object
                shape=[10]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_pos
                shape=[3]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_quat
                shape=[4]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_gripper_qpos
                shape=[2]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            output_shape=[19]
        )
    )
    (mlp): MLP(
        input_dim=7
        output_dim=7
        layer_dims=[136, 544, 272]
        layer_func=Linear
        dropout=None
        act=Mish
        output_act=Tanh
    )
    (policy): MinGPT(
      (model): GPT(
        (tok_emb): Linear(in_features=19, out_features=72, bias=True)
        (drop): Dropout(p=0.1, inplace=False)
        (blocks): Sequential(
          (0): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (1): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (2): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (3): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (ln_f): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
        (head): Linear(in_features=72, out_features=256, bias=False)
      )
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 43%|####2     | 77/180 [00:00<00:00, 769.67it/s] 91%|######### | 163/180 [00:00<00:00, 819.93it/s]100%|##########| 180/180 [00:00<00:00, 807.12it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/8640 [00:00<?, ?it/s] 14%|#4        | 1230/8640 [00:00<00:00, 12296.76it/s] 30%|###       | 2596/8640 [00:00<00:00, 13093.13it/s] 46%|####5     | 3953/8640 [00:00<00:00, 13309.77it/s] 61%|######1   | 5302/8640 [00:00<00:00, 13378.61it/s] 77%|#######7  | 6673/8640 [00:00<00:00, 13496.13it/s] 93%|#########2| 8023/8640 [00:00<00:00, 13426.37it/s]100%|##########| 8640/8640 [00:00<00:00, 13334.47it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 853.39it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/1026 [00:00<?, ?it/s]100%|##########| 1026/1026 [00:00<00:00, 13645.98it/s]

============= Training Dataset =============
SequenceDataset (
	path=datasets/lift/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=5
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=all
	num_demos=180
	num_sequences=8640
)

  0%|          | 0/50 [00:00<?, ?it/s]K-means clustering:   0%|          | 0/50 [00:00<?, ?it/s]K-means clustering:  12%|#2        | 6/50 [00:00<00:00, 59.37it/s]K-means clustering:  24%|##4       | 12/50 [00:00<00:00, 57.25it/s]K-means clustering:  36%|###6      | 18/50 [00:00<00:00, 58.22it/s]K-means clustering:  48%|####8     | 24/50 [00:00<00:00, 57.66it/s]K-means clustering:  60%|######    | 30/50 [00:00<00:00, 57.51it/s]K-means clustering:  72%|#######2  | 36/50 [00:00<00:00, 57.32it/s]K-means clustering:  84%|########4 | 42/50 [00:00<00:00, 57.49it/s]K-means clustering:  96%|#########6| 48/50 [00:00<00:00, 57.64it/s]K-means clustering: 100%|##########| 50/50 [00:00<00:00, 57.68it/s]
  0%|          | 0/100 [00:00<?, ?it/s]/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([100, 5, 7])) that is different to the input size (torch.Size([100, 1, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([100, 5, 7])) that is different to the input size (torch.Size([100, 1, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)
  1%|1         | 1/100 [00:00<00:19,  5.10it/s]  8%|8         | 8/100 [00:00<00:02, 32.26it/s] 16%|#6        | 16/100 [00:00<00:01, 48.51it/s] 24%|##4       | 24/100 [00:00<00:01, 57.65it/s] 32%|###2      | 32/100 [00:00<00:01, 63.02it/s] 40%|####      | 40/100 [00:00<00:00, 66.15it/s] 48%|####8     | 48/100 [00:00<00:00, 68.30it/s] 56%|#####6    | 56/100 [00:00<00:00, 69.80it/s] 64%|######4   | 64/100 [00:01<00:00, 71.37it/s] 72%|#######2  | 72/100 [00:01<00:00, 72.32it/s] 80%|########  | 80/100 [00:01<00:00, 73.22it/s] 88%|########8 | 88/100 [00:01<00:00, 73.83it/s] 96%|#########6| 96/100 [00:01<00:00, 73.99it/s]100%|##########| 100/100 [00:01<00:00, 64.73it/s]
Train Epoch 1
{
    "Cosine_Loss": 1.2068314158916473,
    "L1_Loss": 0.10566983744502068,
    "L2_Loss": 0.21136487826704978,
    "Loss": 78.79042217254639,
    "Policy_Grad_Norms": 0.9999999905100083,
    "Time_Data_Loading": 0.002901748816172282,
    "Time_Epoch": 0.025761008262634277,
    "Time_Log_Info": 7.225672403971354e-05,
    "Time_Process_Batch": 0.00029882589975992836,
    "Time_Train_Batch": 0.022435247898101807
}
  0%|          | 0/10 [00:00<?, ?it/s]100%|##########| 10/10 [00:00<00:00, 198.26it/s]
Validation Epoch 1
{
    "Cosine_Loss": 1.1934056162834168,
    "L1_Loss": 0.10264438688755036,
    "L2_Loss": 0.20531510412693024,
    "Loss": 42.96516304016113,
    "Time_Data_Loading": 0.00028289159138997395,
    "Time_Epoch": 0.0008521199226379395,
    "Time_Log_Info": 2.3305416107177734e-05,
    "Time_Process_Batch": 3.310441970825195e-05,
    "Time_Train_Batch": 0.0004999558130900065
}
video writes to /home/andrew/Desktop/robo_sims/robomimic/robomimic/../bet_trained_models/test/20221130044426/videos/Lift_epoch_1.mp4
rollout: env=Lift, horizon=400, use_goals=False, num_episodes=10
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]
run failed with error:
'ac_encoder'

Traceback (most recent call last):
  File "robomimic/scripts/train.py", line 365, in main
    train(config, device=device)
  File "robomimic/scripts/train.py", line 250, in train
    all_rollout_logs, video_paths = TrainUtils.rollout_with_stats(
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 346, in rollout_with_stats
    rollout_info = run_rollout(
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 213, in run_rollout
    ac = policy(ob=ob_dict, goal=goal_dict)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/algo.py", line 476, in __call__
    ac = self.policy.get_action(obs_dict=ob, goal_dict=goal)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet.py", line 271, in get_action
    enc_obs = self.nets["ac_encoder"](**{"obs":obs_dict})
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/container.py", line 313, in __getitem__
    return self._modules[key]
KeyError: 'ac_encoder'

