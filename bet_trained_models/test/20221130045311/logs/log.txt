
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_quat', 'object', 'robot0_gripper_qpos', 'robot0_eef_pos']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []
/home/andrew/Desktop/robo_sims/robomimic

============= Loaded Environment Metadata =============
obs key object with shape (10,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name Lift
Action size is 7
Lift
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}


============= Model Summary =============
BET (
  ModuleDict(
    (encoder): ObservationBETGroupEncoder(
        group=obs
        ObservationEncoder(
            Key(
                name=object
                shape=[10]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_pos
                shape=[3]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_quat
                shape=[4]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_gripper_qpos
                shape=[2]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            output_shape=[19]
        )
    )
    (ac_encoder): ObservationGroupEncoder(
        group=obs
        ObservationEncoder(
            Key(
                name=object
                shape=[10]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_pos
                shape=[3]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_eef_quat
                shape=[4]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            Key(
                name=robot0_gripper_qpos
                shape=[2]
                modality=low_dim
                randomizer=None
                net=None
                sharing_from=None
            )
            output_shape=[19]
        )
    )
    (mlp): MLP(
        input_dim=7
        output_dim=7
        layer_dims=[136, 544, 272]
        layer_func=Linear
        dropout=None
        act=Mish
        output_act=Tanh
    )
    (policy): MinGPT(
      (model): GPT(
        (tok_emb): Linear(in_features=19, out_features=72, bias=True)
        (drop): Dropout(p=0.1, inplace=False)
        (blocks): Sequential(
          (0): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (1): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (2): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (3): Block(
            (ln1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=72, out_features=72, bias=True)
              (query): Linear(in_features=72, out_features=72, bias=True)
              (value): Linear(in_features=72, out_features=72, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=72, out_features=72, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=72, out_features=288, bias=True)
              (1): GELU()
              (2): Linear(in_features=288, out_features=72, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (ln_f): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
        (head): Linear(in_features=72, out_features=256, bias=False)
      )
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 43%|####2     | 77/180 [00:00<00:00, 767.72it/s] 89%|########8 | 160/180 [00:00<00:00, 801.37it/s]100%|##########| 180/180 [00:00<00:00, 773.66it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/8640 [00:00<?, ?it/s] 15%|#4        | 1277/8640 [00:00<00:00, 12768.92it/s] 30%|###       | 2617/8640 [00:00<00:00, 13138.28it/s] 46%|####5     | 3940/8640 [00:00<00:00, 13177.23it/s] 61%|######1   | 5282/8640 [00:00<00:00, 13270.69it/s] 77%|#######6  | 6646/8640 [00:00<00:00, 13400.46it/s] 92%|#########2| 7990/8640 [00:00<00:00, 13410.07it/s]100%|##########| 8640/8640 [00:00<00:00, 13336.06it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 851.75it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/1026 [00:00<?, ?it/s]100%|##########| 1026/1026 [00:00<00:00, 13496.87it/s]

============= Training Dataset =============
SequenceDataset (
	path=datasets/lift/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=5
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=all
	num_demos=180
	num_sequences=8640
)

  0%|          | 0/50 [00:00<?, ?it/s]K-means clustering:   0%|          | 0/50 [00:00<?, ?it/s]K-means clustering:  10%|#         | 5/50 [00:00<00:00, 47.99it/s]K-means clustering:  22%|##2       | 11/50 [00:00<00:00, 53.88it/s]K-means clustering:  34%|###4      | 17/50 [00:00<00:00, 55.18it/s]K-means clustering:  46%|####6     | 23/50 [00:00<00:00, 55.78it/s]K-means clustering:  58%|#####8    | 29/50 [00:00<00:00, 55.27it/s]K-means clustering:  70%|#######   | 35/50 [00:00<00:00, 56.55it/s]K-means clustering:  82%|########2 | 41/50 [00:00<00:00, 56.55it/s]K-means clustering:  94%|#########3| 47/50 [00:00<00:00, 57.23it/s]K-means clustering: 100%|##########| 50/50 [00:00<00:00, 56.17it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  1%|1         | 1/100 [00:00<00:18,  5.31it/s]  9%|9         | 9/100 [00:00<00:02, 36.36it/s] 17%|#7        | 17/100 [00:00<00:01, 51.36it/s] 25%|##5       | 25/100 [00:00<00:01, 59.75it/s] 33%|###3      | 33/100 [00:00<00:01, 64.84it/s] 41%|####1     | 41/100 [00:00<00:00, 68.25it/s] 49%|####9     | 49/100 [00:00<00:00, 69.16it/s] 57%|#####6    | 57/100 [00:00<00:00, 69.51it/s] 65%|######5   | 65/100 [00:01<00:00, 69.62it/s] 73%|#######3  | 73/100 [00:01<00:00, 69.73it/s] 81%|########1 | 81/100 [00:01<00:00, 69.81it/s] 89%|########9 | 89/100 [00:01<00:00, 71.40it/s] 97%|#########7| 97/100 [00:01<00:00, 72.59it/s]100%|##########| 100/100 [00:01<00:00, 64.69it/s]
Train Epoch 1
{
    "Cosine_Loss": 1.2061015498638152,
    "L1_Loss": 0.10566168554127216,
    "L2_Loss": 0.2113483852148056,
    "Loss": 78.7904273223877,
    "Policy_Grad_Norms": 0.9999999974611709,
    "Time_Data_Loading": 0.0028964559237162272,
    "Time_Epoch": 0.025775432586669922,
    "Time_Log_Info": 7.878541946411133e-05,
    "Time_Process_Batch": 0.00029833316802978515,
    "Time_Train_Batch": 0.022448404630025228
}
  0%|          | 0/10 [00:00<?, ?it/s]100%|##########| 10/10 [00:00<00:00, 217.18it/s]
Validation Epoch 1
{
    "Cosine_Loss": 1.1947231054306031,
    "L1_Loss": 0.10264436602592468,
    "L2_Loss": 0.20531368255615234,
    "Loss": 42.96516418457031,
    "Time_Data_Loading": 0.0002808968226114909,
    "Time_Epoch": 0.0007770498593648275,
    "Time_Log_Info": 6.953875223795573e-06,
    "Time_Process_Batch": 2.8403600056966147e-05,
    "Time_Train_Batch": 0.0004499355951944987
}
video writes to /home/andrew/Desktop/robo_sims/robomimic/robomimic/../bet_trained_models/test/20221130045311/videos/Lift_epoch_1.mp4
rollout: env=Lift, horizon=400, use_goals=False, num_episodes=10
  0%|          | 0/10 [00:00<?, ?it/s]torch.Size([1, 1, 7])
  0%|          | 0/10 [00:00<?, ?it/s]
run failed with error:
environment got invalid action dimension -- expected 7, got 1

Traceback (most recent call last):
  File "robomimic/scripts/train.py", line 365, in main
    train(config, device=device)
  File "robomimic/scripts/train.py", line 250, in train
    all_rollout_logs, video_paths = TrainUtils.rollout_with_stats(
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 346, in rollout_with_stats
    rollout_info = run_rollout(
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 216, in run_rollout
    ob_dict, r, done, _ = env.step(ac)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/envs/env_robosuite.py", line 104, in step
    obs, r, done, info = self.env.step(action)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/robosuite/environments/base.py", line 406, in step
    self._pre_action(action, policy_step)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/robosuite/environments/robot_env.py", line 575, in _pre_action
    assert len(action) == self.action_dim, "environment got invalid action dimension -- expected {}, got {}".format(
AssertionError: environment got invalid action dimension -- expected 7, got 1

