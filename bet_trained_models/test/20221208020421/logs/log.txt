
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_eef_pos', 'object']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []
/home/andrew/Desktop/robo_sims/robomimic

============= Loaded Environment Metadata =============
obs key object with shape (14,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name NutAssemblySquare
Action size is 7
NutAssemblySquare
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}


============= Model Summary =============
BET (
  ModuleDict(
    (mlp): MLP(
        input_dim=7
        output_dim=7
        layer_dims=[512, 512]
        layer_func=Linear
        dropout=None
        act=Mish
        output_act=Tanh
    )
    (policy): MinGPT(
      (model): GPT(
        (tok_emb): Linear(in_features=26, out_features=120, bias=True)
        (drop): Dropout(p=0.1, inplace=False)
        (blocks): Sequential(
          (0): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (1): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (2): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (3): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (4): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (5): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (ln_f): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
        (head): Linear(in_features=120, out_features=512, bias=False)
      )
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 46%|####6     | 83/180 [00:00<00:00, 823.27it/s] 92%|#########2| 166/180 [00:00<00:00, 807.78it/s]100%|##########| 180/180 [00:00<00:00, 808.91it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 798.51it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 46%|####5     | 82/180 [00:00<00:00, 810.97it/s] 91%|#########1| 164/180 [00:00<00:00, 805.05it/s]100%|##########| 180/180 [00:00<00:00, 802.24it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 841.55it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 44%|####3     | 79/180 [00:00<00:00, 785.46it/s] 91%|######### | 163/180 [00:00<00:00, 813.35it/s]100%|##########| 180/180 [00:00<00:00, 805.09it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 821.57it/s]

============= Training Dataset =============
[SequenceDataset (
	path=datasets/square/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=27165
), SequenceDataset (
	path=/home/andrew/Desktop/robo_sims/robomimic/datasets/can/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=20883
), SequenceDataset (
	path=/home/andrew/Desktop/robo_sims/robomimic/datasets/lift/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=8640
)]

  0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:   0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:   2%|2         | 2/100 [00:00<00:05, 19.17it/s]K-means clustering:   5%|5         | 5/100 [00:00<00:04, 21.05it/s]K-means clustering:   8%|8         | 8/100 [00:00<00:04, 22.44it/s]K-means clustering:  11%|#1        | 11/100 [00:00<00:03, 22.82it/s]K-means clustering:  14%|#4        | 14/100 [00:00<00:03, 23.14it/s]K-means clustering:  17%|#7        | 17/100 [00:00<00:03, 23.42it/s]K-means clustering:  20%|##        | 20/100 [00:00<00:03, 23.78it/s]K-means clustering:  23%|##3       | 23/100 [00:00<00:03, 23.94it/s]K-means clustering:  26%|##6       | 26/100 [00:01<00:03, 23.89it/s]K-means clustering:  29%|##9       | 29/100 [00:01<00:02, 23.91it/s]K-means clustering:  32%|###2      | 32/100 [00:01<00:02, 23.76it/s]K-means clustering:  35%|###5      | 35/100 [00:01<00:02, 23.83it/s]K-means clustering:  38%|###8      | 38/100 [00:01<00:02, 23.61it/s]K-means clustering:  41%|####1     | 41/100 [00:01<00:02, 23.61it/s]K-means clustering:  44%|####4     | 44/100 [00:01<00:02, 23.68it/s]K-means clustering:  47%|####6     | 47/100 [00:02<00:02, 22.59it/s]K-means clustering:  50%|#####     | 50/100 [00:02<00:02, 22.90it/s]K-means clustering:  53%|#####3    | 53/100 [00:02<00:02, 23.19it/s]K-means clustering:  56%|#####6    | 56/100 [00:02<00:01, 23.09it/s]K-means clustering:  59%|#####8    | 59/100 [00:02<00:01, 23.23it/s]K-means clustering:  62%|######2   | 62/100 [00:02<00:01, 23.35it/s]K-means clustering:  65%|######5   | 65/100 [00:02<00:01, 23.31it/s]K-means clustering:  68%|######8   | 68/100 [00:02<00:01, 23.37it/s]K-means clustering:  71%|#######1  | 71/100 [00:03<00:01, 22.99it/s]K-means clustering:  74%|#######4  | 74/100 [00:03<00:01, 22.67it/s]K-means clustering:  77%|#######7  | 77/100 [00:03<00:01, 22.76it/s]K-means clustering:  80%|########  | 80/100 [00:03<00:00, 22.67it/s]K-means clustering:  83%|########2 | 83/100 [00:03<00:00, 22.56it/s]K-means clustering:  86%|########6 | 86/100 [00:03<00:00, 22.21it/s]K-means clustering:  89%|########9 | 89/100 [00:03<00:00, 22.19it/s]K-means clustering:  92%|#########2| 92/100 [00:03<00:00, 22.30it/s]K-means clustering:  95%|#########5| 95/100 [00:04<00:00, 22.58it/s]K-means clustering:  98%|#########8| 98/100 [00:04<00:00, 22.60it/s]K-means clustering: 100%|##########| 100/100 [00:04<00:00, 23.01it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  1%|1         | 1/100 [00:00<00:20,  4.83it/s]  5%|5         | 5/100 [00:00<00:05, 17.96it/s]  9%|9         | 9/100 [00:00<00:03, 24.46it/s] 13%|#3        | 13/100 [00:00<00:03, 28.44it/s] 17%|#7        | 17/100 [00:00<00:02, 30.93it/s] 21%|##1       | 21/100 [00:00<00:02, 32.56it/s] 25%|##5       | 25/100 [00:00<00:02, 33.72it/s] 29%|##9       | 29/100 [00:00<00:02, 34.63it/s] 33%|###3      | 33/100 [00:01<00:01, 35.30it/s] 37%|###7      | 37/100 [00:01<00:01, 35.62it/s] 41%|####1     | 41/100 [00:01<00:01, 35.63it/s] 45%|####5     | 45/100 [00:01<00:01, 35.68it/s] 49%|####9     | 49/100 [00:01<00:01, 35.79it/s] 53%|#####3    | 53/100 [00:01<00:01, 35.93it/s] 57%|#####6    | 57/100 [00:01<00:01, 36.03it/s] 61%|######1   | 61/100 [00:01<00:01, 36.16it/s] 65%|######5   | 65/100 [00:01<00:00, 36.08it/s] 69%|######9   | 69/100 [00:02<00:00, 35.86it/s] 73%|#######3  | 73/100 [00:02<00:00, 35.73it/s] 77%|#######7  | 77/100 [00:02<00:00, 35.45it/s] 81%|########1 | 81/100 [00:02<00:00, 35.42it/s] 85%|########5 | 85/100 [00:02<00:00, 35.27it/s] 89%|########9 | 89/100 [00:02<00:00, 35.17it/s] 93%|#########3| 93/100 [00:02<00:00, 34.79it/s] 97%|#########7| 97/100 [00:02<00:00, 34.84it/s]100%|##########| 100/100 [00:02<00:00, 33.46it/s]
Train Epoch 1
{
    "Cosine_Loss": 0.6051820707321167,
    "L1_Loss": 0.08540521241724491,
    "L2_Loss": 0.175328523889184,
    "Loss": 3.5238406324386595,
    "Policy_Grad_Norms": 0.9999995515487128,
    "Time_Data_Loading": 0.01688856283823649,
    "Time_Epoch": 0.04981913169225057,
    "Time_Log_Info": 0.00012808640797932943,
    "Time_Process_Batch": 0.0006762425104777019,
    "Time_Train_Batch": 0.032037413120269774
}
  0%|          | 0/20 [00:00<?, ?it/s] 35%|###5      | 7/20 [00:00<00:00, 66.83it/s] 70%|#######   | 14/20 [00:00<00:00, 67.96it/s]100%|##########| 20/20 [00:00<00:00, 67.97it/s]
Validation Epoch 1
{
    "Cosine_Loss": 0.38925581276416776,
    "L1_Loss": 0.048548201099038124,
    "L2_Loss": 0.10378561876714229,
    "Loss": 2.9908979654312136,
    "Time_Data_Loading": 0.0034326950709025065,
    "Time_Epoch": 0.004917438824971517,
    "Time_Log_Info": 1.556873321533203e-05,
    "Time_Process_Batch": 0.00013236602147420246,
    "Time_Train_Batch": 0.0013154904047648112
}

Epoch 1 Memory Usage: 3670 MB

  0%|          | 0/100 [00:00<?, ?it/s]  4%|4         | 4/100 [00:00<00:02, 34.05it/s]  8%|8         | 8/100 [00:00<00:02, 33.58it/s] 12%|#2        | 12/100 [00:00<00:02, 34.09it/s] 16%|#6        | 16/100 [00:00<00:02, 34.49it/s] 20%|##        | 20/100 [00:00<00:02, 34.55it/s] 24%|##4       | 24/100 [00:00<00:02, 34.75it/s] 28%|##8       | 28/100 [00:00<00:02, 34.82it/s] 32%|###2      | 32/100 [00:00<00:02, 33.40it/s] 36%|###6      | 36/100 [00:01<00:01, 33.21it/s] 40%|####      | 40/100 [00:01<00:01, 33.56it/s] 44%|####4     | 44/100 [00:01<00:01, 33.96it/s] 48%|####8     | 48/100 [00:01<00:01, 34.47it/s] 52%|#####2    | 52/100 [00:01<00:01, 33.10it/s] 56%|#####6    | 56/100 [00:01<00:01, 33.90it/s] 60%|######    | 60/100 [00:01<00:01, 34.22it/s] 64%|######4   | 64/100 [00:01<00:01, 34.19it/s] 68%|######8   | 68/100 [00:01<00:00, 34.53it/s] 70%|#######   | 70/100 [00:02<00:00, 33.91it/s]
Traceback (most recent call last):
  File "robomimic/scripts/multitask_train.py", line 422, in <module>
    main(args)
  File "robomimic/scripts/multitask_train.py", line 373, in main
    train(config, device=device)
  File "robomimic/scripts/multitask_train.py", line 196, in train
    step_log = TrainUtils.run_epoch(model=model, data_loader=train_loader, epoch=epoch, num_steps=train_num_steps)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 541, in run_epoch
    info = model.train_on_batch(input_batch, epoch, validate=validate)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet.py", line 212, in train_on_batch
    sa, so, loss = self.nets["policy"].get_latent_and_loss(obs_rep=enc_outputs, target_latents=latent, return_loss_components=True)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet_models/generators.py", line 103, in get_latent_and_loss
    output, _ = self.model(obs_rep)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet_models/libraries/mingpt/model.py", line 240, in forward
    x = self.blocks(x)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet_models/libraries/mingpt/model.py", line 122, in forward
    x = x + self.attn(self.ln1(x))
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet_models/libraries/mingpt/model.py", line 92, in forward
    att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))
KeyboardInterrupt
