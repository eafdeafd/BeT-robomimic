
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_quat', 'robot0_eef_pos', 'object', 'robot0_gripper_qpos']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []
/home/andrew/Desktop/robo_sims/robomimic

============= Loaded Environment Metadata =============
obs key object with shape (14,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name NutAssemblySquare
Action size is 7
NutAssemblySquare
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}
Created environment with name PickPlaceCan
Action size is 7
PickPlaceCan
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}
Created environment with name Lift
Action size is 7
Lift
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}


============= Model Summary =============
BET (
  ModuleDict(
    (mlp): MLP(
        input_dim=7
        output_dim=7
        layer_dims=[512, 512]
        layer_func=Linear
        dropout=None
        act=Mish
        output_act=Tanh
    )
    (policy): MinGPT(
      (model): GPT(
        (tok_emb): Linear(in_features=26, out_features=120, bias=True)
        (drop): Dropout(p=0.1, inplace=False)
        (blocks): Sequential(
          (0): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (1): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (2): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (3): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (4): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (5): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (ln_f): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
        (head): Linear(in_features=120, out_features=512, bias=False)
      )
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 46%|####5     | 82/180 [00:00<00:00, 813.66it/s] 92%|#########1| 165/180 [00:00<00:00, 818.05it/s]100%|##########| 180/180 [00:00<00:00, 819.52it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 837.10it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 45%|####5     | 81/180 [00:00<00:00, 805.08it/s] 91%|######### | 163/180 [00:00<00:00, 813.75it/s]100%|##########| 180/180 [00:00<00:00, 811.92it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 859.12it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 46%|####5     | 82/180 [00:00<00:00, 816.59it/s] 91%|#########1| 164/180 [00:00<00:00, 818.07it/s]100%|##########| 180/180 [00:00<00:00, 816.28it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 820.42it/s]

============= Training Dataset =============
[SequenceDataset (
	path=datasets/square/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=27165
), SequenceDataset (
	path=/home/andrew/Desktop/robo_sims/robomimic/datasets/can/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=20883
), SequenceDataset (
	path=/home/andrew/Desktop/robo_sims/robomimic/datasets/lift/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=8640
)]

  0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:   0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:   2%|2         | 2/100 [00:00<00:05, 18.24it/s]K-means clustering:   4%|4         | 4/100 [00:00<00:05, 18.66it/s]K-means clustering:   7%|7         | 7/100 [00:00<00:04, 20.67it/s]K-means clustering:  10%|#         | 10/100 [00:00<00:04, 21.91it/s]K-means clustering:  13%|#3        | 13/100 [00:00<00:03, 22.44it/s]K-means clustering:  16%|#6        | 16/100 [00:00<00:03, 22.06it/s]K-means clustering:  19%|#9        | 19/100 [00:00<00:03, 22.29it/s]K-means clustering:  22%|##2       | 22/100 [00:01<00:03, 22.61it/s]K-means clustering:  25%|##5       | 25/100 [00:01<00:03, 22.35it/s]K-means clustering:  28%|##8       | 28/100 [00:01<00:03, 21.65it/s]K-means clustering:  31%|###1      | 31/100 [00:01<00:03, 21.43it/s]K-means clustering:  34%|###4      | 34/100 [00:01<00:03, 21.22it/s]K-means clustering:  37%|###7      | 37/100 [00:01<00:02, 21.62it/s]K-means clustering:  40%|####      | 40/100 [00:01<00:02, 21.94it/s]K-means clustering:  43%|####3     | 43/100 [00:01<00:02, 21.44it/s]K-means clustering:  46%|####6     | 46/100 [00:02<00:02, 21.57it/s]K-means clustering:  49%|####9     | 49/100 [00:02<00:02, 21.74it/s]K-means clustering:  52%|#####2    | 52/100 [00:02<00:02, 21.85it/s]K-means clustering:  55%|#####5    | 55/100 [00:02<00:02, 22.14it/s]K-means clustering:  58%|#####8    | 58/100 [00:02<00:01, 22.18it/s]K-means clustering:  61%|######1   | 61/100 [00:02<00:01, 22.57it/s]K-means clustering:  64%|######4   | 64/100 [00:02<00:01, 22.71it/s]K-means clustering:  67%|######7   | 67/100 [00:03<00:01, 22.83it/s]K-means clustering:  70%|#######   | 70/100 [00:03<00:01, 23.06it/s]K-means clustering:  73%|#######3  | 73/100 [00:03<00:01, 23.10it/s]K-means clustering:  76%|#######6  | 76/100 [00:03<00:01, 23.22it/s]K-means clustering:  79%|#######9  | 79/100 [00:03<00:00, 23.10it/s]K-means clustering:  82%|########2 | 82/100 [00:03<00:00, 23.33it/s]K-means clustering:  85%|########5 | 85/100 [00:03<00:00, 23.31it/s]K-means clustering:  88%|########8 | 88/100 [00:03<00:00, 23.40it/s]K-means clustering:  91%|#########1| 91/100 [00:04<00:00, 22.82it/s]K-means clustering:  94%|#########3| 94/100 [00:04<00:00, 22.15it/s]K-means clustering:  97%|#########7| 97/100 [00:04<00:00, 22.21it/s]K-means clustering: 100%|##########| 100/100 [00:04<00:00, 22.45it/s]K-means clustering: 100%|##########| 100/100 [00:04<00:00, 22.24it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  1%|1         | 1/100 [00:00<00:19,  5.13it/s]  6%|6         | 6/100 [00:00<00:03, 23.85it/s] 11%|#1        | 11/100 [00:00<00:02, 32.24it/s] 15%|#5        | 15/100 [00:00<00:02, 34.84it/s] 20%|##        | 20/100 [00:00<00:02, 38.39it/s] 25%|##5       | 25/100 [00:00<00:01, 39.72it/s] 31%|###1      | 31/100 [00:00<00:01, 43.54it/s] 37%|###7      | 37/100 [00:00<00:01, 45.64it/s] 42%|####2     | 42/100 [00:01<00:01, 46.50it/s] 48%|####8     | 48/100 [00:01<00:01, 47.70it/s] 54%|#####4    | 54/100 [00:01<00:00, 48.61it/s] 60%|######    | 60/100 [00:01<00:00, 49.24it/s] 66%|######6   | 66/100 [00:01<00:00, 49.67it/s] 71%|#######1  | 71/100 [00:01<00:00, 49.72it/s] 76%|#######6  | 76/100 [00:01<00:00, 49.78it/s] 82%|########2 | 82/100 [00:01<00:00, 49.97it/s] 88%|########8 | 88/100 [00:01<00:00, 50.37it/s] 94%|#########3| 94/100 [00:02<00:00, 49.69it/s] 99%|#########9| 99/100 [00:02<00:00, 47.79it/s]100%|##########| 100/100 [00:02<00:00, 44.38it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  5%|5         | 5/100 [00:00<00:02, 42.74it/s] 10%|#         | 10/100 [00:00<00:02, 42.29it/s] 16%|#6        | 16/100 [00:00<00:01, 46.02it/s] 21%|##1       | 21/100 [00:00<00:01, 47.20it/s] 27%|##7       | 27/100 [00:00<00:01, 47.90it/s] 33%|###3      | 33/100 [00:00<00:01, 48.91it/s] 39%|###9      | 39/100 [00:00<00:01, 49.73it/s] 44%|####4     | 44/100 [00:00<00:01, 49.76it/s] 50%|#####     | 50/100 [00:01<00:01, 49.98it/s] 55%|#####5    | 55/100 [00:01<00:00, 47.41it/s] 60%|######    | 60/100 [00:01<00:00, 46.59it/s] 65%|######5   | 65/100 [00:01<00:00, 45.04it/s] 70%|#######   | 70/100 [00:01<00:00, 40.81it/s] 75%|#######5  | 75/100 [00:01<00:00, 41.65it/s] 80%|########  | 80/100 [00:01<00:00, 40.81it/s] 86%|########6 | 86/100 [00:01<00:00, 43.86it/s] 91%|#########1| 91/100 [00:01<00:00, 45.42it/s] 96%|#########6| 96/100 [00:02<00:00, 46.63it/s]100%|##########| 100/100 [00:02<00:00, 46.00it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  5%|5         | 5/100 [00:00<00:02, 44.64it/s] 10%|#         | 10/100 [00:00<00:01, 45.38it/s] 15%|#5        | 15/100 [00:00<00:01, 46.89it/s] 20%|##        | 20/100 [00:00<00:01, 45.33it/s] 25%|##5       | 25/100 [00:00<00:01, 43.98it/s] 30%|###       | 30/100 [00:00<00:01, 45.69it/s] 35%|###5      | 35/100 [00:00<00:01, 46.83it/s] 40%|####      | 40/100 [00:00<00:01, 47.51it/s] 45%|####5     | 45/100 [00:00<00:01, 48.02it/s] 50%|#####     | 50/100 [00:01<00:01, 48.09it/s] 55%|#####5    | 55/100 [00:01<00:00, 48.19it/s] 60%|######    | 60/100 [00:01<00:00, 48.17it/s] 65%|######5   | 65/100 [00:01<00:00, 48.45it/s] 70%|#######   | 70/100 [00:01<00:00, 46.07it/s] 75%|#######5  | 75/100 [00:01<00:00, 43.82it/s] 80%|########  | 80/100 [00:01<00:00, 43.53it/s] 85%|########5 | 85/100 [00:01<00:00, 44.33it/s] 90%|######### | 90/100 [00:01<00:00, 45.34it/s] 95%|#########5| 95/100 [00:02<00:00, 46.59it/s]100%|##########| 100/100 [00:02<00:00, 47.41it/s]100%|##########| 100/100 [00:02<00:00, 46.37it/s]
Train Epoch 1
{
    "Cosine_Loss": 0.6393036643664042,
    "L1_Loss": 0.09860896805301309,
    "L2_Loss": 0.20218651389082273,
    "Loss": 4.040816536744436,
    "Policy_Grad_Norms": 0.9999996216838993,
    "Time_Data_Loading": 0.016759995619455972,
    "Time_Epoch": 0.10974899927775066,
    "Time_Log_Info": 0.00027559598286946616,
    "Time_Process_Batch": 0.0015597939491271973,
    "Time_Train_Batch": 0.09091970920562745
}
  0%|          | 0/20 [00:00<?, ?it/s] 80%|########  | 16/20 [00:00<00:00, 153.15it/s]100%|##########| 20/20 [00:00<00:00, 152.74it/s]
  0%|          | 0/20 [00:00<?, ?it/s] 80%|########  | 16/20 [00:00<00:00, 153.35it/s]100%|##########| 20/20 [00:00<00:00, 153.29it/s]
  0%|          | 0/20 [00:00<?, ?it/s] 80%|########  | 16/20 [00:00<00:00, 150.05it/s]100%|##########| 20/20 [00:00<00:00, 150.61it/s]
Validation Epoch 1
{
    "Cosine_Loss": 0.751221752166748,
    "L1_Loss": 0.10060184293737014,
    "L2_Loss": 0.22511862789591153,
    "Loss": 4.297973370552063,
    "Time_Data_Loading": 0.003034830093383789,
    "Time_Epoch": 0.006593775749206543,
    "Time_Log_Info": 3.9072831471761066e-05,
    "Time_Process_Batch": 0.00026387770970662434,
    "Time_Train_Batch": 0.003221313158671061
}
video writes to /home/andrew/Desktop/robo_sims/robomimic/robomimic/../bet_trained_models/test/20221208153816/videos/NutAssemblySquare_epoch_1.mp4
rollout: env=NutAssemblySquare, horizon=300, use_goals=False, num_episodes=20
  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]
run failed with error:
can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.

Traceback (most recent call last):
  File "robomimic/scripts/multitask_train.py", line 376, in main
    train(config, device=device)
  File "robomimic/scripts/multitask_train.py", line 260, in train
    all_rollout_logs, video_paths = TrainUtils.rollout_with_stats(
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 350, in rollout_with_stats
    rollout_info = run_rollout(
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 214, in run_rollout
    ac = policy(ob=ob_dict, goal=goal_dict)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/algo.py", line 476, in __call__
    ac = self.policy.get_action(obs_dict=ob, goal_dict=goal)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet.py", line 302, in get_action
    enc_obs = self._format_input(enc_obs , self.env_name) if self.multi_task else enc_obs
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet.py", line 150, in _format_input
    x = torch.tensor(np.array(x))
TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.

