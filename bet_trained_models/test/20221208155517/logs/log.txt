
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_quat', 'robot0_eef_pos', 'object', 'robot0_gripper_qpos']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []
/home/andrew/Desktop/robo_sims/robomimic

============= Loaded Environment Metadata =============
obs key object with shape (14,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name NutAssemblySquare
Action size is 7
NutAssemblySquare
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}
Created environment with name PickPlaceCan
Action size is 7
PickPlaceCan
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}
Created environment with name Lift
Action size is 7
Lift
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}


============= Model Summary =============
BET (
  ModuleDict(
    (mlp): MLP(
        input_dim=7
        output_dim=7
        layer_dims=[512, 512]
        layer_func=Linear
        dropout=None
        act=Mish
        output_act=Tanh
    )
    (policy): MinGPT(
      (model): GPT(
        (tok_emb): Linear(in_features=26, out_features=120, bias=True)
        (drop): Dropout(p=0.1, inplace=False)
        (blocks): Sequential(
          (0): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (1): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (2): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (3): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (4): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (5): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (ln_f): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
        (head): Linear(in_features=120, out_features=512, bias=False)
      )
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 39%|###8      | 70/180 [00:00<00:00, 699.54it/s] 78%|#######7  | 140/180 [00:00<00:00, 675.44it/s]100%|##########| 180/180 [00:00<00:00, 681.16it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 672.21it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 38%|###7      | 68/180 [00:00<00:00, 679.77it/s] 82%|########2 | 148/180 [00:00<00:00, 745.78it/s]100%|##########| 180/180 [00:00<00:00, 739.22it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 844.38it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 47%|####7     | 85/180 [00:00<00:00, 842.47it/s] 94%|#########4| 170/180 [00:00<00:00, 844.19it/s]100%|##########| 180/180 [00:00<00:00, 837.01it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 802.74it/s]

============= Training Dataset =============
[SequenceDataset (
	path=datasets/square/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=27165
), SequenceDataset (
	path=/home/andrew/Desktop/robo_sims/robomimic/datasets/can/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=20883
), SequenceDataset (
	path=/home/andrew/Desktop/robo_sims/robomimic/datasets/lift/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=8640
)]

  0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:   0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:   2%|2         | 2/100 [00:00<00:05, 17.18it/s]K-means clustering:   4%|4         | 4/100 [00:00<00:05, 17.19it/s]K-means clustering:   6%|6         | 6/100 [00:00<00:05, 17.18it/s]K-means clustering:   8%|8         | 8/100 [00:00<00:05, 17.19it/s]K-means clustering:  10%|#         | 10/100 [00:00<00:05, 17.38it/s]K-means clustering:  12%|#2        | 12/100 [00:00<00:04, 17.79it/s]K-means clustering:  14%|#4        | 14/100 [00:00<00:04, 18.42it/s]K-means clustering:  17%|#7        | 17/100 [00:00<00:04, 19.80it/s]K-means clustering:  20%|##        | 20/100 [00:01<00:03, 20.20it/s]K-means clustering:  23%|##3       | 23/100 [00:01<00:03, 20.58it/s]K-means clustering:  26%|##6       | 26/100 [00:01<00:03, 20.95it/s]K-means clustering:  29%|##9       | 29/100 [00:01<00:03, 21.23it/s]K-means clustering:  32%|###2      | 32/100 [00:01<00:03, 21.46it/s]K-means clustering:  35%|###5      | 35/100 [00:01<00:03, 21.28it/s]K-means clustering:  38%|###8      | 38/100 [00:01<00:02, 21.54it/s]K-means clustering:  41%|####1     | 41/100 [00:02<00:02, 21.78it/s]K-means clustering:  44%|####4     | 44/100 [00:02<00:02, 21.69it/s]K-means clustering:  47%|####6     | 47/100 [00:02<00:02, 21.76it/s]K-means clustering:  50%|#####     | 50/100 [00:02<00:02, 21.98it/s]K-means clustering:  53%|#####3    | 53/100 [00:02<00:02, 22.11it/s]K-means clustering:  56%|#####6    | 56/100 [00:02<00:01, 22.24it/s]K-means clustering:  59%|#####8    | 59/100 [00:02<00:01, 22.21it/s]K-means clustering:  62%|######2   | 62/100 [00:02<00:01, 22.13it/s]K-means clustering:  65%|######5   | 65/100 [00:03<00:01, 21.49it/s]K-means clustering:  68%|######8   | 68/100 [00:03<00:01, 21.42it/s]K-means clustering:  71%|#######1  | 71/100 [00:03<00:01, 21.74it/s]K-means clustering:  74%|#######4  | 74/100 [00:03<00:01, 21.97it/s]K-means clustering:  77%|#######7  | 77/100 [00:03<00:01, 22.14it/s]K-means clustering:  80%|########  | 80/100 [00:03<00:00, 22.23it/s]K-means clustering:  83%|########2 | 83/100 [00:03<00:00, 22.33it/s]K-means clustering:  86%|########6 | 86/100 [00:04<00:00, 22.42it/s]K-means clustering:  89%|########9 | 89/100 [00:04<00:00, 22.53it/s]K-means clustering:  92%|#########2| 92/100 [00:04<00:00, 22.60it/s]K-means clustering:  95%|#########5| 95/100 [00:04<00:00, 22.41it/s]K-means clustering:  98%|#########8| 98/100 [00:04<00:00, 22.49it/s]K-means clustering: 100%|##########| 100/100 [00:04<00:00, 21.33it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  1%|1         | 1/100 [00:00<00:20,  4.79it/s]  6%|6         | 6/100 [00:00<00:04, 22.67it/s] 11%|#1        | 11/100 [00:00<00:02, 31.95it/s] 16%|#6        | 16/100 [00:00<00:02, 37.36it/s] 21%|##1       | 21/100 [00:00<00:01, 40.03it/s] 26%|##6       | 26/100 [00:00<00:01, 42.38it/s] 31%|###1      | 31/100 [00:00<00:01, 44.34it/s] 36%|###6      | 36/100 [00:00<00:01, 45.51it/s] 41%|####1     | 41/100 [00:01<00:01, 45.42it/s] 46%|####6     | 46/100 [00:01<00:01, 45.46it/s] 51%|#####1    | 51/100 [00:01<00:01, 44.80it/s] 56%|#####6    | 56/100 [00:01<00:00, 44.68it/s] 61%|######1   | 61/100 [00:01<00:00, 44.67it/s] 66%|######6   | 66/100 [00:01<00:00, 45.41it/s] 71%|#######1  | 71/100 [00:01<00:00, 45.76it/s] 76%|#######6  | 76/100 [00:01<00:00, 45.98it/s] 81%|########1 | 81/100 [00:01<00:00, 46.12it/s] 86%|########6 | 86/100 [00:02<00:00, 46.19it/s] 91%|#########1| 91/100 [00:02<00:00, 46.54it/s] 96%|#########6| 96/100 [00:02<00:00, 46.92it/s]100%|##########| 100/100 [00:02<00:00, 42.74it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  5%|5         | 5/100 [00:00<00:02, 44.85it/s] 10%|#         | 10/100 [00:00<00:01, 47.04it/s] 15%|#5        | 15/100 [00:00<00:01, 47.35it/s] 20%|##        | 20/100 [00:00<00:01, 45.49it/s] 25%|##5       | 25/100 [00:00<00:01, 43.95it/s] 30%|###       | 30/100 [00:00<00:01, 43.57it/s] 35%|###5      | 35/100 [00:00<00:01, 45.10it/s] 40%|####      | 40/100 [00:00<00:01, 45.92it/s] 45%|####5     | 45/100 [00:00<00:01, 46.26it/s] 50%|#####     | 50/100 [00:01<00:01, 46.66it/s] 55%|#####5    | 55/100 [00:01<00:00, 46.33it/s] 60%|######    | 60/100 [00:01<00:00, 46.48it/s] 65%|######5   | 65/100 [00:01<00:00, 47.09it/s] 70%|#######   | 70/100 [00:01<00:00, 46.66it/s] 75%|#######5  | 75/100 [00:01<00:00, 46.11it/s] 80%|########  | 80/100 [00:01<00:00, 45.20it/s] 85%|########5 | 85/100 [00:01<00:00, 46.52it/s] 90%|######### | 90/100 [00:01<00:00, 47.48it/s] 96%|#########6| 96/100 [00:02<00:00, 48.80it/s]100%|##########| 100/100 [00:02<00:00, 46.65it/s]
  0%|          | 0/100 [00:00<?, ?it/s]  5%|5         | 5/100 [00:00<00:01, 49.14it/s] 10%|#         | 10/100 [00:00<00:01, 48.73it/s] 15%|#5        | 15/100 [00:00<00:01, 49.11it/s] 20%|##        | 20/100 [00:00<00:01, 49.14it/s] 25%|##5       | 25/100 [00:00<00:01, 49.35it/s] 30%|###       | 30/100 [00:00<00:01, 49.21it/s] 35%|###5      | 35/100 [00:00<00:01, 49.44it/s] 40%|####      | 40/100 [00:00<00:01, 49.61it/s] 46%|####6     | 46/100 [00:00<00:01, 49.88it/s] 51%|#####1    | 51/100 [00:01<00:00, 49.13it/s] 56%|#####6    | 56/100 [00:01<00:00, 47.08it/s] 61%|######1   | 61/100 [00:01<00:00, 45.46it/s] 66%|######6   | 66/100 [00:01<00:00, 45.62it/s] 71%|#######1  | 71/100 [00:01<00:00, 46.17it/s] 76%|#######6  | 76/100 [00:01<00:00, 46.98it/s] 81%|########1 | 81/100 [00:01<00:00, 47.32it/s] 86%|########6 | 86/100 [00:01<00:00, 47.93it/s] 92%|#########2| 92/100 [00:01<00:00, 48.86it/s] 97%|#########7| 97/100 [00:02<00:00, 48.76it/s]100%|##########| 100/100 [00:02<00:00, 48.19it/s]
Train Epoch 1
{
    "Cosine_Loss": 0.6393036643664042,
    "L1_Loss": 0.09860896805301309,
    "L2_Loss": 0.20218651389082273,
    "Loss": 4.040816536744436,
    "Policy_Grad_Norms": 0.9999996216838993,
    "Time_Data_Loading": 0.016201635201772053,
    "Time_Epoch": 0.10933747291564941,
    "Time_Log_Info": 0.0003857533137003581,
    "Time_Process_Batch": 0.0016298294067382812,
    "Time_Train_Batch": 0.09087581237157186
}
  0%|          | 0/20 [00:00<?, ?it/s] 75%|#######5  | 15/20 [00:00<00:00, 148.39it/s]100%|##########| 20/20 [00:00<00:00, 147.90it/s]
  0%|          | 0/20 [00:00<?, ?it/s] 80%|########  | 16/20 [00:00<00:00, 152.52it/s]100%|##########| 20/20 [00:00<00:00, 152.16it/s]
  0%|          | 0/20 [00:00<?, ?it/s] 75%|#######5  | 15/20 [00:00<00:00, 147.20it/s]100%|##########| 20/20 [00:00<00:00, 148.42it/s]
Validation Epoch 1
{
    "Cosine_Loss": 0.751221752166748,
    "L1_Loss": 0.10060184293737014,
    "L2_Loss": 0.22511862789591153,
    "Loss": 4.297973370552063,
    "Time_Data_Loading": 0.002993273735046387,
    "Time_Epoch": 0.006710565090179444,
    "Time_Log_Info": 4.357099533081055e-05,
    "Time_Process_Batch": 0.00029538869857788087,
    "Time_Train_Batch": 0.003346745173136393
}
video writes to /home/andrew/Desktop/robo_sims/robomimic/robomimic/../bet_trained_models/test/20221208155517/videos/NutAssemblySquare_epoch_1.mp4
rollout: env=NutAssemblySquare, horizon=300, use_goals=False, num_episodes=20
  0%|          | 0/20 [00:00<?, ?it/s]Ture
NutAssemblySquare
  0%|          | 0/20 [00:00<?, ?it/s]
run failed with error:
can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.

Traceback (most recent call last):
  File "robomimic/scripts/multitask_train.py", line 376, in main
    train(config, device=device)
  File "robomimic/scripts/multitask_train.py", line 260, in train
    all_rollout_logs, video_paths = TrainUtils.rollout_with_stats(
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 352, in rollout_with_stats
    rollout_info = run_rollout(
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 214, in run_rollout
    ac = policy(ob=ob_dict, goal=goal_dict)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/algo.py", line 476, in __call__
    ac = self.policy.get_action(obs_dict=ob, goal_dict=goal)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet.py", line 306, in get_action
    enc_obs = self._format_input(enc_obs, self.env_name) if self.multi_task else enc_obs
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet.py", line 150, in _format_input
    x = torch.tensor(np.array(x))
TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.

