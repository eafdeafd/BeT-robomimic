
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_eef_quat', 'robot0_eef_pos', 'robot0_gripper_qpos', 'object']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []
/home/andrew/Desktop/robo_sims/robomimic

============= Loaded Environment Metadata =============
obs key object with shape (14,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)
Created environment with name NutAssemblySquare
Action size is 7
NutAssemblySquare
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}
Created environment with name PickPlaceCan
Action size is 7
PickPlaceCan
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}
Created environment with name Lift
Action size is 7
Lift
{
    "camera_depths": false,
    "camera_heights": 84,
    "camera_widths": 84,
    "control_freq": 20,
    "controller_configs": {
        "control_delta": true,
        "damping": 1,
        "damping_limits": [
            0,
            10
        ],
        "impedance_mode": "fixed",
        "input_max": 1,
        "input_min": -1,
        "interpolation": null,
        "kp": 150,
        "kp_limits": [
            0,
            300
        ],
        "orientation_limits": null,
        "output_max": [
            0.05,
            0.05,
            0.05,
            0.5,
            0.5,
            0.5
        ],
        "output_min": [
            -0.05,
            -0.05,
            -0.05,
            -0.5,
            -0.5,
            -0.5
        ],
        "position_limits": null,
        "ramp_ratio": 0.2,
        "type": "OSC_POSE",
        "uncouple_pos_ori": true
    },
    "has_offscreen_renderer": true,
    "has_renderer": false,
    "ignore_done": true,
    "render_gpu_device_id": 0,
    "reward_shaping": false,
    "robots": [
        "Panda"
    ],
    "use_camera_obs": false,
    "use_object_obs": true
}


============= Model Summary =============
BET (
  ModuleDict(
    (mlp): MLP(
        input_dim=7
        output_dim=7
        layer_dims=[512, 512]
        layer_func=Linear
        dropout=None
        act=Mish
        output_act=Tanh
    )
    (policy): MinGPT(
      (model): GPT(
        (tok_emb): Linear(in_features=26, out_features=120, bias=True)
        (drop): Dropout(p=0.1, inplace=False)
        (blocks): Sequential(
          (0): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (1): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (2): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (3): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (4): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
          (5): Block(
            (ln1): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (ln2): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
            (attn): CausalSelfAttention(
              (key): Linear(in_features=120, out_features=120, bias=True)
              (query): Linear(in_features=120, out_features=120, bias=True)
              (value): Linear(in_features=120, out_features=120, bias=True)
              (attn_drop): Dropout(p=0.1, inplace=False)
              (resid_drop): Dropout(p=0.1, inplace=False)
              (proj): Linear(in_features=120, out_features=120, bias=True)
            )
            (mlp): Sequential(
              (0): Linear(in_features=120, out_features=480, bias=True)
              (1): GELU()
              (2): Linear(in_features=480, out_features=120, bias=True)
              (3): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (ln_f): LayerNorm((120,), eps=1e-05, elementwise_affine=True)
        (head): Linear(in_features=120, out_features=512, bias=False)
      )
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 46%|####6     | 83/180 [00:00<00:00, 820.79it/s] 92%|#########2| 166/180 [00:00<00:00, 822.66it/s]100%|##########| 180/180 [00:00<00:00, 820.45it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 818.06it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 47%|####6     | 84/180 [00:00<00:00, 838.54it/s] 93%|#########3| 168/180 [00:00<00:00, 837.56it/s]100%|##########| 180/180 [00:00<00:00, 835.81it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 862.21it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/180 [00:00<?, ?it/s] 48%|####8     | 87/180 [00:00<00:00, 860.96it/s] 97%|#########6| 174/180 [00:00<00:00, 860.79it/s]100%|##########| 180/180 [00:00<00:00, 860.55it/s]
SequenceDataset: loading dataset into memory...
  0%|          | 0/20 [00:00<?, ?it/s]100%|##########| 20/20 [00:00<00:00, 856.11it/s]

============= Training Dataset =============
[SequenceDataset (
	path=datasets/square/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=27165
), SequenceDataset (
	path=/home/andrew/Desktop/robo_sims/robomimic/datasets/can/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=20883
), SequenceDataset (
	path=/home/andrew/Desktop/robo_sims/robomimic/datasets/lift/ph/low_dim.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=10
	filter_key=train
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=low_dim
	num_demos=180
	num_sequences=8640
)]

  0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:   0%|          | 0/100 [00:00<?, ?it/s]K-means clustering:   3%|3         | 3/100 [00:00<00:04, 23.36it/s]K-means clustering:   6%|6         | 6/100 [00:00<00:04, 22.07it/s]K-means clustering:   9%|9         | 9/100 [00:00<00:04, 20.62it/s]K-means clustering:  12%|#2        | 12/100 [00:00<00:04, 21.77it/s]K-means clustering:  15%|#5        | 15/100 [00:00<00:03, 22.01it/s]K-means clustering:  18%|#8        | 18/100 [00:00<00:03, 21.97it/s]K-means clustering:  21%|##1       | 21/100 [00:00<00:03, 22.30it/s]K-means clustering:  24%|##4       | 24/100 [00:01<00:03, 22.44it/s]K-means clustering:  27%|##7       | 27/100 [00:01<00:03, 22.64it/s]K-means clustering:  30%|###       | 30/100 [00:01<00:03, 22.76it/s]K-means clustering:  33%|###3      | 33/100 [00:01<00:02, 22.53it/s]K-means clustering:  36%|###6      | 36/100 [00:01<00:02, 22.63it/s]K-means clustering:  39%|###9      | 39/100 [00:01<00:02, 22.58it/s]K-means clustering:  42%|####2     | 42/100 [00:01<00:02, 23.02it/s]K-means clustering:  45%|####5     | 45/100 [00:02<00:02, 23.09it/s]K-means clustering:  48%|####8     | 48/100 [00:02<00:02, 22.92it/s]K-means clustering:  51%|#####1    | 51/100 [00:02<00:02, 23.28it/s]K-means clustering:  54%|#####4    | 54/100 [00:02<00:01, 23.68it/s]K-means clustering:  57%|#####6    | 57/100 [00:02<00:01, 23.92it/s]K-means clustering:  60%|######    | 60/100 [00:02<00:01, 23.90it/s]K-means clustering:  63%|######3   | 63/100 [00:02<00:01, 24.06it/s]K-means clustering:  66%|######6   | 66/100 [00:02<00:01, 23.97it/s]K-means clustering:  69%|######9   | 69/100 [00:03<00:01, 24.00it/s]K-means clustering:  72%|#######2  | 72/100 [00:03<00:01, 23.27it/s]K-means clustering:  75%|#######5  | 75/100 [00:03<00:01, 23.09it/s]K-means clustering:  78%|#######8  | 78/100 [00:03<00:01, 21.95it/s]K-means clustering:  81%|########1 | 81/100 [00:03<00:00, 22.62it/s]K-means clustering:  84%|########4 | 84/100 [00:03<00:00, 22.33it/s]K-means clustering:  87%|########7 | 87/100 [00:03<00:00, 22.60it/s]K-means clustering:  90%|######### | 90/100 [00:03<00:00, 23.08it/s]K-means clustering:  93%|#########3| 93/100 [00:04<00:00, 23.40it/s]K-means clustering:  96%|#########6| 96/100 [00:04<00:00, 23.31it/s]K-means clustering:  99%|#########9| 99/100 [00:04<00:00, 22.96it/s]K-means clustering: 100%|##########| 100/100 [00:04<00:00, 22.90it/s]
  0%|          | 0/100 [00:00<?, ?it/s]square
torch.Size([30, 10, 23])
  0%|          | 0/100 [00:00<?, ?it/s]
run failed with error:
mat1 and mat2 shapes cannot be multiplied (300x30 and 26x120)

Traceback (most recent call last):
  File "robomimic/scripts/multitask_train.py", line 376, in main
    train(config, device=device)
  File "robomimic/scripts/multitask_train.py", line 199, in train
    step_log = TrainUtils.run_multi_epoch(model=model, data_loader=trainloaders, epoch=epoch, num_steps=train_num_steps)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/utils/train_utils.py", line 628, in run_multi_epoch
    info = model.train_on_batch(input_batch, epoch, validate=validate)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet.py", line 216, in train_on_batch
    sa, so, loss = self.nets["policy"].get_latent_and_loss(obs_rep=enc_outputs, target_latents=latent, return_loss_components=True)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet_models/generators.py", line 103, in get_latent_and_loss
    output, _ = self.model(obs_rep)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/andrew/Desktop/robo_sims/robomimic/robomimic/algo/bet_models/libraries/mingpt/model.py", line 235, in forward
    token_embeddings = self.tok_emb(idx)  # each index maps to a (learnable) vector
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/andrew/anaconda3/envs/behavior-transformer/lib/python3.8/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (300x30 and 26x120)

